{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9c95e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "386ca22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "Data_set = np.loadtxt('./ThoraricSurgery.csv', delimiter=',')\n",
    "\n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d667dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 입력 17개 출력 30개 (동그라미 30개)\n",
    "model.add(Dense(30, input_dim = 17, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977a040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.8213\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 996us/step - loss: 0.4681 - accuracy: 0.8447\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 931us/step - loss: 0.4362 - accuracy: 0.8447\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8511\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 933us/step - loss: 0.4482 - accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8489\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8511\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.8511\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4311 - accuracy: 0.8532\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 979us/step - loss: 0.4408 - accuracy: 0.8489\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8511\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.4713 - accuracy: 0.8234\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 872us/step - loss: 0.4551 - accuracy: 0.8468\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.4334 - accuracy: 0.8468\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 870us/step - loss: 0.4474 - accuracy: 0.8298\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 859us/step - loss: 0.4806 - accuracy: 0.8447\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4510 - accuracy: 0.8404\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4345 - accuracy: 0.8447\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4248 - accuracy: 0.8468\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.4149 - accuracy: 0.8489\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 884us/step - loss: 0.4618 - accuracy: 0.8255\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4362 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 858us/step - loss: 0.4419 - accuracy: 0.8489\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 914us/step - loss: 0.4630 - accuracy: 0.8340\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4218 - accuracy: 0.8468\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4378 - accuracy: 0.8489\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 930us/step - loss: 0.4119 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 907us/step - loss: 0.4463 - accuracy: 0.8489\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8489\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 939us/step - loss: 0.4731 - accuracy: 0.8383\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8511\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8383\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4304 - accuracy: 0.8489\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4322 - accuracy: 0.8426\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 870us/step - loss: 0.4427 - accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4300 - accuracy: 0.8553\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 864us/step - loss: 0.4175 - accuracy: 0.8468\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 906us/step - loss: 0.4865 - accuracy: 0.8319\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8447\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 908us/step - loss: 0.4112 - accuracy: 0.8404\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4151 - accuracy: 0.8468\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 915us/step - loss: 0.4138 - accuracy: 0.8468\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4349 - accuracy: 0.8234\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 939us/step - loss: 0.4235 - accuracy: 0.8383\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 947us/step - loss: 0.4109 - accuracy: 0.8447\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 909us/step - loss: 0.4109 - accuracy: 0.8447\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 828us/step - loss: 0.4165 - accuracy: 0.8468\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8596\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 948us/step - loss: 0.4099 - accuracy: 0.8489\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4127 - accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 953us/step - loss: 0.4238 - accuracy: 0.8426\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 980us/step - loss: 0.4054 - accuracy: 0.8511\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 848us/step - loss: 0.4147 - accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.4202 - accuracy: 0.8532\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4039 - accuracy: 0.8468\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.3979 - accuracy: 0.8489\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 949us/step - loss: 0.4057 - accuracy: 0.8553\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4099 - accuracy: 0.8468\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8426\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.4489 - accuracy: 0.8362\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8489\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8383\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8489\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4205 - accuracy: 0.8468\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8468\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4151 - accuracy: 0.8489\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8553\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 891us/step - loss: 0.4418 - accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 888us/step - loss: 0.4516 - accuracy: 0.8489\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4075 - accuracy: 0.8489\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8489\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8426\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.4111 - accuracy: 0.8383\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8511\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8362\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8426\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1000us/step - loss: 0.4553 - accuracy: 0.8404\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8489\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.4169 - accuracy: 0.8468\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 848us/step - loss: 0.4241 - accuracy: 0.8404\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.3971 - accuracy: 0.8447\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 986us/step - loss: 0.4162 - accuracy: 0.8362\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.3971 - accuracy: 0.8489\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.3948 - accuracy: 0.8489\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 869us/step - loss: 0.4222 - accuracy: 0.8574\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 979us/step - loss: 0.4399 - accuracy: 0.8489\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 923us/step - loss: 0.4173 - accuracy: 0.8426\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 892us/step - loss: 0.4300 - accuracy: 0.8468\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.4098 - accuracy: 0.8468\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8468\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8298\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8362\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4116 - accuracy: 0.8362\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 936us/step - loss: 0.3982 - accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18856c7abb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# epochs = 훈련 수 batch_size = 데이터 조각내서 훈련 (데이터/숫자)\n",
    "model.fit(X,Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681576b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./pima-indians-diabetes.csv', names = ['pregnant','plasma','pressure',\n",
    "                                                    'thickness','insulin','BMI','pedigree',\n",
    "                                                    'age','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e75164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
      "0         6     148        72         35        0  33.6     0.627   50      1\n",
      "1         1      85        66         29        0  26.6     0.351   31      0\n",
      "2         8     183        64          0        0  23.3     0.672   32      1\n",
      "3         1      89        66         23       94  28.1     0.167   21      0\n",
      "4         0     137        40         35      168  43.1     2.288   33      1\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ff255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  \\\n",
       "0           6     148        72         35        0  33.6     0.627   50   \n",
       "1           1      85        66         29        0  26.6     0.351   31   \n",
       "2           8     183        64          0        0  23.3     0.672   32   \n",
       "3           1      89        66         23       94  28.1     0.167   21   \n",
       "4           0     137        40         35      168  43.1     2.288   33   \n",
       "..        ...     ...       ...        ...      ...   ...       ...  ...   \n",
       "763        10     101        76         48      180  32.9     0.171   63   \n",
       "764         2     122        70         27        0  36.8     0.340   27   \n",
       "765         5     121        72         23      112  26.2     0.245   30   \n",
       "766         1     126        60          0        0  30.1     0.349   47   \n",
       "767         1      93        70         31        0  30.4     0.315   23   \n",
       "\n",
       "     class  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "763      0  \n",
       "764      0  \n",
       "765      0  \n",
       "766      1  \n",
       "767      0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92e4de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant      plasma    pressure   thickness     insulin         BMI  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7792e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  class\n",
       "0           6      1\n",
       "1           1      0\n",
       "2           8      1\n",
       "3           1      0\n",
       "4           0      1\n",
       "..        ...    ...\n",
       "763        10      0\n",
       "764         2      0\n",
       "765         5      0\n",
       "766         1      1\n",
       "767         1      0\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['pregnant','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b676172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pregnant     class\n",
      "0          0  0.342342\n",
      "1          1  0.214815\n",
      "2          2  0.184466\n",
      "3          3  0.360000\n",
      "4          4  0.338235\n",
      "5          5  0.368421\n",
      "6          6  0.320000\n",
      "7          7  0.555556\n",
      "8          8  0.578947\n",
      "9          9  0.642857\n",
      "10        10  0.416667\n",
      "11        11  0.636364\n",
      "12        12  0.444444\n",
      "13        13  0.500000\n",
      "14        14  1.000000\n",
      "15        15  1.000000\n",
      "16        17  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[['pregnant','class']].groupby(['pregnant'], as_index=False).mean().sort_values(by='pregnant', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba3ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(df, col='class')\n",
    "grid.map(plt.hist, 'plasma', bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e357d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "dataset = np.loadtxt('./pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6e88310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "981771ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 16.5846 - accuracy: 0.6523\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 990us/step - loss: 2.0059 - accuracy: 0.5573\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 999us/step - loss: 1.2442 - accuracy: 0.5365\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 966us/step - loss: 1.0700 - accuracy: 0.5846\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9790 - accuracy: 0.5911\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.8930 - accuracy: 0.5977\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.8371 - accuracy: 0.6328\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 965us/step - loss: 0.8395 - accuracy: 0.6146\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.8512 - accuracy: 0.6224\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8249 - accuracy: 0.6224\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 919us/step - loss: 0.7641 - accuracy: 0.6341\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6432\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6497\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.7531 - accuracy: 0.6419\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 972us/step - loss: 0.6986 - accuracy: 0.6471\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.7197 - accuracy: 0.6719\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.6738 - accuracy: 0.6680\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 934us/step - loss: 0.6721 - accuracy: 0.6862\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.7063 - accuracy: 0.6628\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.6889 - accuracy: 0.6732\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.6728 - accuracy: 0.6562\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.6609 - accuracy: 0.6628\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 944us/step - loss: 0.6832 - accuracy: 0.6602\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6797\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.6992\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6979\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 805us/step - loss: 0.6798 - accuracy: 0.6732\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.6345 - accuracy: 0.6979\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.6540 - accuracy: 0.6888\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.6161 - accuracy: 0.7070\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6927\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.7096\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6953\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.6090 - accuracy: 0.7005\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.6171 - accuracy: 0.7214\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.6587 - accuracy: 0.7005\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.5932 - accuracy: 0.7201\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.6997 - accuracy: 0.6810\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.6657 - accuracy: 0.6914\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.5875 - accuracy: 0.7201\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.5958 - accuracy: 0.7161\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.6543 - accuracy: 0.6940\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 892us/step - loss: 0.5853 - accuracy: 0.7122\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.5672 - accuracy: 0.7201\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.5917 - accuracy: 0.7227\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 892us/step - loss: 0.6285 - accuracy: 0.7201\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 934us/step - loss: 0.5927 - accuracy: 0.7057\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.7253\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.6056 - accuracy: 0.7122\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 871us/step - loss: 0.5992 - accuracy: 0.7096\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.5560 - accuracy: 0.7383\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7370\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.6422 - accuracy: 0.6901\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 965us/step - loss: 0.6120 - accuracy: 0.7044\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.6013 - accuracy: 0.7201\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.7201\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7292\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.5391 - accuracy: 0.7318\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7148\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7370\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.5499 - accuracy: 0.7214\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.5713 - accuracy: 0.7214\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7227\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 972us/step - loss: 0.5639 - accuracy: 0.7383\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 907us/step - loss: 0.5769 - accuracy: 0.7044\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 915us/step - loss: 0.5567 - accuracy: 0.7240\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 938us/step - loss: 0.5724 - accuracy: 0.7396\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.5486 - accuracy: 0.7448\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7409\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.5287 - accuracy: 0.7409\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.5565 - accuracy: 0.7253\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 945us/step - loss: 0.5210 - accuracy: 0.7318\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 965us/step - loss: 0.5395 - accuracy: 0.7227\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 909us/step - loss: 0.5355 - accuracy: 0.7422\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.5660 - accuracy: 0.7161\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.5737 - accuracy: 0.7227\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.5343 - accuracy: 0.7383\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.6335 - accuracy: 0.7096\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.5972 - accuracy: 0.7135\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 927us/step - loss: 0.5453 - accuracy: 0.7422\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 904us/step - loss: 0.5401 - accuracy: 0.7292\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 944us/step - loss: 0.5661 - accuracy: 0.7318\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.5288 - accuracy: 0.7461\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5359 - accuracy: 0.7604\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.5261 - accuracy: 0.7461\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.5410 - accuracy: 0.7474\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 910us/step - loss: 0.5246 - accuracy: 0.7396\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.5309 - accuracy: 0.7422\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 907us/step - loss: 0.5342 - accuracy: 0.7370\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7174\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 921us/step - loss: 0.5886 - accuracy: 0.7357\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 915us/step - loss: 0.5895 - accuracy: 0.7253\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 931us/step - loss: 0.5060 - accuracy: 0.7513\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.5238 - accuracy: 0.7526\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.5354 - accuracy: 0.7383\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 892us/step - loss: 0.5302 - accuracy: 0.7513\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.5305 - accuracy: 0.7604\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.5588 - accuracy: 0.7370\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5308 - accuracy: 0.7370\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5194 - accuracy: 0.7617\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5298 - accuracy: 0.7487\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 886us/step - loss: 0.5136 - accuracy: 0.7565\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 919us/step - loss: 0.5466 - accuracy: 0.7435\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.5548 - accuracy: 0.7357\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.5023 - accuracy: 0.7578\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 915us/step - loss: 0.5661 - accuracy: 0.7370\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 929us/step - loss: 0.5182 - accuracy: 0.7565\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.5269 - accuracy: 0.7604\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.5278 - accuracy: 0.7578\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.5152 - accuracy: 0.7409\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.5274 - accuracy: 0.7526\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.5256 - accuracy: 0.7357\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.5147 - accuracy: 0.7435\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 0.5063 - accuracy: 0.7760\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 865us/step - loss: 0.5248 - accuracy: 0.7552\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.5261 - accuracy: 0.7565\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.5191 - accuracy: 0.7656\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 889us/step - loss: 0.5002 - accuracy: 0.7630\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 928us/step - loss: 0.5529 - accuracy: 0.7370\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5399 - accuracy: 0.7383\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 904us/step - loss: 0.5260 - accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.5575 - accuracy: 0.7318\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 883us/step - loss: 0.4935 - accuracy: 0.7669\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 921us/step - loss: 0.5401 - accuracy: 0.7539\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7734\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 887us/step - loss: 0.5015 - accuracy: 0.7695\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 879us/step - loss: 0.5068 - accuracy: 0.7708\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.5961 - accuracy: 0.7344\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 0.5083 - accuracy: 0.7773\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 931us/step - loss: 0.4922 - accuracy: 0.7539\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7734\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 919us/step - loss: 0.5056 - accuracy: 0.7604\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5138 - accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7604\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 923us/step - loss: 0.5333 - accuracy: 0.7591\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.5095 - accuracy: 0.7656\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 959us/step - loss: 0.4933 - accuracy: 0.7760\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.5632 - accuracy: 0.7370\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7552\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7773\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.5026 - accuracy: 0.7578\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.5112 - accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.5166 - accuracy: 0.7526\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.5016 - accuracy: 0.7617\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7734\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7682\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.5289 - accuracy: 0.7487\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7669\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.4880 - accuracy: 0.7643\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.4816 - accuracy: 0.7812\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.4696 - accuracy: 0.7747\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7578\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 978us/step - loss: 0.5076 - accuracy: 0.7656\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.5036 - accuracy: 0.7708\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7773\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.5202 - accuracy: 0.7578\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 0.4973 - accuracy: 0.7799\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 907us/step - loss: 0.4818 - accuracy: 0.7630\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7435\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 945us/step - loss: 0.4982 - accuracy: 0.7539\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.4837 - accuracy: 0.7773\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.4892 - accuracy: 0.7930\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 942us/step - loss: 0.6083 - accuracy: 0.7370\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 0.4847 - accuracy: 0.7669\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.4897 - accuracy: 0.7695\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.4716 - accuracy: 0.7812\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 0.4880 - accuracy: 0.7799\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.4785 - accuracy: 0.7799\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 895us/step - loss: 0.4729 - accuracy: 0.7773\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7604\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7747\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.4625 - accuracy: 0.7865\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 880us/step - loss: 0.4629 - accuracy: 0.7891\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 868us/step - loss: 0.4613 - accuracy: 0.7904\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.4726 - accuracy: 0.7760\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.4976 - accuracy: 0.7786\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 946us/step - loss: 0.5081 - accuracy: 0.7721\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 922us/step - loss: 0.5505 - accuracy: 0.7513\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 875us/step - loss: 0.4843 - accuracy: 0.7682\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.4868 - accuracy: 0.7826\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 887us/step - loss: 0.5043 - accuracy: 0.7656\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.4679 - accuracy: 0.7799\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.4679 - accuracy: 0.7878\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.4878 - accuracy: 0.7747\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 908us/step - loss: 0.4707 - accuracy: 0.7734\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.4881 - accuracy: 0.7786\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.5068 - accuracy: 0.7734\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 0.4659 - accuracy: 0.7852\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 926us/step - loss: 0.4987 - accuracy: 0.7721\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 0.4843 - accuracy: 0.7734\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7721\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 0.4703 - accuracy: 0.7799\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 921us/step - loss: 0.4807 - accuracy: 0.7682\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7786\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 926us/step - loss: 0.4807 - accuracy: 0.7669\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7799\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7799\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7995\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 861us/step - loss: 0.4960 - accuracy: 0.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1885a5efa00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "950332a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8073\n",
      "\n",
      " Accuracy : 0.8073\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy : %.4f' %(model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6829d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('./iris.csv', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width','species'])\n",
    "dataset = df.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y1 = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3176f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee2ccec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y데이터 인코딩\n",
    "Y1 = Y1.reshape(-1,1)\n",
    "\n",
    "oh_enc = OneHotEncoder()\n",
    "oh_enc.fit(Y1)\n",
    "Y = oh_enc.transform(Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7ac2ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=3, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "890da488",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('./iris.csv', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width','species'])\n",
    "dataset = df.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y1 = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a43d91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = LabelEncoder()\n",
    "e.fit(Y1)\n",
    "Y = e.transform(Y1)\n",
    "Y_encoded = tf.keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d781739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e791404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 912us/step - loss: 1.4507 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 827us/step - loss: 1.1518 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 768us/step - loss: 1.0367 - accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 772us/step - loss: 0.9337 - accuracy: 0.5200\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 794us/step - loss: 0.8288 - accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 812us/step - loss: 0.7287 - accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 797us/step - loss: 0.6456 - accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 847us/step - loss: 0.5869 - accuracy: 0.7400\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 824us/step - loss: 0.5372 - accuracy: 0.7200\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 777us/step - loss: 0.4980 - accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 801us/step - loss: 0.4638 - accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 781us/step - loss: 0.4329 - accuracy: 0.8667\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 782us/step - loss: 0.4127 - accuracy: 0.8933\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 802us/step - loss: 0.3825 - accuracy: 0.9000\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 759us/step - loss: 0.3606 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 822us/step - loss: 0.3394 - accuracy: 0.9400\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 731us/step - loss: 0.3244 - accuracy: 0.9400\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.3125 - accuracy: 0.9533\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 810us/step - loss: 0.2887 - accuracy: 0.9600\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 835us/step - loss: 0.2728 - accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 803us/step - loss: 0.2600 - accuracy: 0.9800\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 782us/step - loss: 0.2515 - accuracy: 0.9667\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 873us/step - loss: 0.2355 - accuracy: 0.9733\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 851us/step - loss: 0.2281 - accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 782us/step - loss: 0.2125 - accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 753us/step - loss: 0.2050 - accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 776us/step - loss: 0.1966 - accuracy: 0.9667\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 764us/step - loss: 0.1794 - accuracy: 0.9733\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 781us/step - loss: 0.1816 - accuracy: 0.9600\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 798us/step - loss: 0.1781 - accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 831us/step - loss: 0.1697 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 813us/step - loss: 0.1620 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 854us/step - loss: 0.1572 - accuracy: 0.9733\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 819us/step - loss: 0.1499 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 950us/step - loss: 0.1465 - accuracy: 0.9733\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 899us/step - loss: 0.1450 - accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 780us/step - loss: 0.1341 - accuracy: 0.9733\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 640us/step - loss: 0.1366 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 747us/step - loss: 0.1291 - accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 761us/step - loss: 0.1333 - accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 767us/step - loss: 0.1237 - accuracy: 0.9733\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 851us/step - loss: 0.1219 - accuracy: 0.9733\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 812us/step - loss: 0.1205 - accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 768us/step - loss: 0.1153 - accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 831us/step - loss: 0.1215 - accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 811us/step - loss: 0.1145 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 862us/step - loss: 0.1140 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 806us/step - loss: 0.1093 - accuracy: 0.9733\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 885us/step - loss: 0.1068 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 840us/step - loss: 0.1118 - accuracy: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1885fa53df0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y_encoded, epochs=50, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37f2ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9667\n",
      "\n",
      " Accuracy : 0.9667\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy : %.4f' %(model.evaluate(X,Y_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b134536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sonar.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2cb7a031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "381aeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('./sonar.csv', header=None)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y1 = dataset[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61ce9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = LabelEncoder()\n",
    "e.fit(Y1)\n",
    "Y = e.transform(Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cc4e6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f9f60746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 930us/step - loss: 0.6946 - accuracy: 0.5481\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.6058\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6106\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6490\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6971\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 978us/step - loss: 0.6215 - accuracy: 0.7260\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 942us/step - loss: 0.5947 - accuracy: 0.7596\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7548\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 989us/step - loss: 0.5543 - accuracy: 0.7692\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 977us/step - loss: 0.5250 - accuracy: 0.7788\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8029\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 1000us/step - loss: 0.4765 - accuracy: 0.8077\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 977us/step - loss: 0.4592 - accuracy: 0.7981\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8077\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8317\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8173\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8125\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 994us/step - loss: 0.4056 - accuracy: 0.8365\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8365\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 999us/step - loss: 0.3905 - accuracy: 0.8173\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8365\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8413\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8365\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8269\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8462\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8510\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8510\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8317\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8558\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8510\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8510\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8606\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8654\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8558\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8654\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8654\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.8702\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 1000us/step - loss: 0.3009 - accuracy: 0.8894\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8750\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 955us/step - loss: 0.2795 - accuracy: 0.8894\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 951us/step - loss: 0.2876 - accuracy: 0.8750\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 948us/step - loss: 0.2692 - accuracy: 0.8990\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 1000us/step - loss: 0.2762 - accuracy: 0.9135\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8750\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8942\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2521 - accuracy: 0.9135\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 976us/step - loss: 0.2496 - accuracy: 0.9038\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9135\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.9135\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 999us/step - loss: 0.2485 - accuracy: 0.9183\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 974us/step - loss: 0.2371 - accuracy: 0.9231\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 956us/step - loss: 0.2305 - accuracy: 0.9327\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9038\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 938us/step - loss: 0.2352 - accuracy: 0.8990\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 976us/step - loss: 0.2356 - accuracy: 0.9135\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 1000us/step - loss: 0.2214 - accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 937us/step - loss: 0.2141 - accuracy: 0.9375\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9183\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 927us/step - loss: 0.2180 - accuracy: 0.9279\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9471\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9327\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9183\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9327\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9423\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9423\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9231\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9375\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9519\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9471\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9471\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9279\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9423\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9423\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9567\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9663\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9375\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9567\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9567\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9567\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9567\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9615\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9663\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9760\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9663\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9663\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9712\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9712\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9615\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9663\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9615\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9663\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9712\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9615\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9712\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9808\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9663\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9808\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9760\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9856\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9760\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9712\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9760\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9808\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9808\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9760\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9808\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9760\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9808\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9760\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9808\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9808\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9808\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9808\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9808\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9808\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9712\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9856\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9856\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9808\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9856\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9856\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9808\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9856\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9808\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9856\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9856\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9856\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9856\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9904\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9856\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9904\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9904\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9904\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9904\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9904\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9904\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9904\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9904\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9904\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9904\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9904\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9904\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9904\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9904\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9904\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9904\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9904\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9904\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9904\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9952\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9952\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9952\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9952\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9952\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9952\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9952\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9952\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9952\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9952\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9952\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9952\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9952\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9952\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9952\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9952\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9952\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9952\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9952\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9952\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9952\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9952\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18860e6fd00>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5f625483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "\n",
      " Accuracy : 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy : %.4f' %(model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d29354c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7a42f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.4813\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.6837 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.6777 - accuracy: 0.6096\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6096\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6738\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6467 - accuracy: 0.6684\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6204 - accuracy: 0.7166\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7594\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 980us/step - loss: 0.5311 - accuracy: 0.7540\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7754\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7754\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7914\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.4049 - accuracy: 0.8289\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4046 - accuracy: 0.8235\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3874 - accuracy: 0.8128\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8235\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7594\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8342\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8610\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3126 - accuracy: 0.8663\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3150 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3085 - accuracy: 0.8663\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8770\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8663\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 990us/step - loss: 0.2789 - accuracy: 0.8877\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2727 - accuracy: 0.8824\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2837 - accuracy: 0.8556\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 942us/step - loss: 0.2668 - accuracy: 0.8984\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2644 - accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2569 - accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.8984\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 937us/step - loss: 0.2597 - accuracy: 0.8824\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.8877\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9091\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2387 - accuracy: 0.9037\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2320 - accuracy: 0.8877\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2276 - accuracy: 0.9037\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2275 - accuracy: 0.9144\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 952us/step - loss: 0.2183 - accuracy: 0.9251\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9144\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2174 - accuracy: 0.9251\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 938us/step - loss: 0.2120 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2164 - accuracy: 0.9251\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9251\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9251\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9091\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9037\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9412\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9144\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9305\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9358\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9412\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9198\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1685 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1689 - accuracy: 0.9519\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9251\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1657 - accuracy: 0.9572\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9412\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9198\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9412\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9572\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1458 - accuracy: 0.9519\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9251\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9572\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9626\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1321 - accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9519\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1376 - accuracy: 0.9679\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1346 - accuracy: 0.9572\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.1283 - accuracy: 0.9679\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9679\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9626\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1290 - accuracy: 0.9519\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1149 - accuracy: 0.9679\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4449 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.4599\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.6862 - accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.6828 - accuracy: 0.5882\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.6524\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6684 - accuracy: 0.6738\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 997us/step - loss: 0.6590 - accuracy: 0.7112\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.6459 - accuracy: 0.6845\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6308 - accuracy: 0.7380\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.7380\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.7380\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7326\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7594\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7540\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8021\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 959us/step - loss: 0.4840 - accuracy: 0.7914\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7701\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8128\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8075\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4147 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 979us/step - loss: 0.4221 - accuracy: 0.8075\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3905 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8396\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3589 - accuracy: 0.8396\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8289\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3454 - accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8503\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8503\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8556\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8663\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 990us/step - loss: 0.3134 - accuracy: 0.8717\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8717\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2935 - accuracy: 0.8717\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8824\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 0.2647 - accuracy: 0.8877\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9144\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2356 - accuracy: 0.9251\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9198\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.8930\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2133 - accuracy: 0.9305\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9358\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2011 - accuracy: 0.9251\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9358\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9572\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9519\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9412\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9358\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9305\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9465\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9519\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9465\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9572\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1726 - accuracy: 0.9251\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.1586 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 999us/step - loss: 0.1378 - accuracy: 0.9572\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9626\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9786\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9679\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1250 - accuracy: 0.9626\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.1108 - accuracy: 0.9733\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1049 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1170 - accuracy: 0.9572\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.1142 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0984 - accuracy: 0.9840\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0952 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0786 - accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0789 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0953 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 935us/step - loss: 0.0718 - accuracy: 0.9893\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0665 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0707 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0684 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0796 - accuracy: 0.9679\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0635 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.0623 - accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0604 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 979us/step - loss: 0.0595 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9947\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 981us/step - loss: 0.0510 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0528 - accuracy: 0.9893\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x0000018864561790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6583 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.4866\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6655 - accuracy: 0.5561\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6952\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.7326\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.7166\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7433\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7861\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7754\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7594\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7754\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7807\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.4420 - accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4256 - accuracy: 0.8342\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 963us/step - loss: 0.4164 - accuracy: 0.8342\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4055 - accuracy: 0.8289\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8449\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8449\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8663\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4007 - accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.3634 - accuracy: 0.8503\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.3447 - accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8770\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3202 - accuracy: 0.8824\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.9037\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8984\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.9037\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8877\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.9091\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8930\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8984\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.9198\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.9251\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9358\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.9144\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9358\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9305\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2355 - accuracy: 0.9305\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2295 - accuracy: 0.9412\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 960us/step - loss: 0.2342 - accuracy: 0.9358\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9358\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9358\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9358\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9091\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9519\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 991us/step - loss: 0.1858 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9412\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9412\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9465\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9519\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9519\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1758 - accuracy: 0.9465\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9465\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.1502 - accuracy: 0.9465\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9519\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9519\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9465\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1315 - accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1367 - accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9572\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9679\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9572\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1242 - accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 979us/step - loss: 0.1164 - accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9679\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9626\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9679\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1045 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9679\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9840\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9840\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001886568D040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8176 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.6698 - accuracy: 0.6471\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6559 - accuracy: 0.6310\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.7380\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.7326\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.6011 - accuracy: 0.7540\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 965us/step - loss: 0.5836 - accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.5416 - accuracy: 0.7433\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 983us/step - loss: 0.5248 - accuracy: 0.7807\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7861\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8342\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 959us/step - loss: 0.4659 - accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7914\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4508 - accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.4422 - accuracy: 0.8289\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 959us/step - loss: 0.4298 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.4250 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.4177 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4426 - accuracy: 0.7754\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8396\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8396\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8289\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8449\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3664 - accuracy: 0.8449\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 957us/step - loss: 0.3504 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8503\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3320 - accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8770\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8663\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3126 - accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8877\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8930\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8877\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8877\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8984\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2808 - accuracy: 0.8877\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2799 - accuracy: 0.8930\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2675 - accuracy: 0.8984\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.2598 - accuracy: 0.8984\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 0.2513 - accuracy: 0.9091\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8984\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.9037\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9144\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9091\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9198\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2195 - accuracy: 0.9198\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2105 - accuracy: 0.9091\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 971us/step - loss: 0.2083 - accuracy: 0.9305\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9198\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9144\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9412\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.8877\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9412\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9251\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9305\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9412\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9465\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9144\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9358\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9465\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9519\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.1420 - accuracy: 0.9626\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9519\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9572\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9733\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9412\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 988us/step - loss: 0.1164 - accuracy: 0.9840\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9679\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1049 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9733\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3934 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5668\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6845\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6578\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.7005\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6038 - accuracy: 0.7166\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7540\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7701\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8128\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4886 - accuracy: 0.8075\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7861\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4609 - accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7968\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8235\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 999us/step - loss: 0.4273 - accuracy: 0.8128\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8449\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8021\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8342\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.7914\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.7968\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8342\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.3418 - accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3314 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 989us/step - loss: 0.3284 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8610\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 975us/step - loss: 0.3155 - accuracy: 0.8770\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.3031 - accuracy: 0.8877\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3045 - accuracy: 0.8717\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8770\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8877\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8770\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8984\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8930\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2756 - accuracy: 0.8824\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 982us/step - loss: 0.2622 - accuracy: 0.9037\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8984\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9037\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9305\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 978us/step - loss: 0.2341 - accuracy: 0.8984\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9198\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9037\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9091\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2078 - accuracy: 0.9251\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.2102 - accuracy: 0.9198\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.8984\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9198\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9251\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9412\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 978us/step - loss: 0.1757 - accuracy: 0.9358\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9305\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9358\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9305\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9465\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9519\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9572\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1559 - accuracy: 0.9465\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9465\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9465\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9412\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9412\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1429 - accuracy: 0.9465\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1336 - accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 956us/step - loss: 0.1335 - accuracy: 0.9572\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9679\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9572\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9679\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9679\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9572\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 992us/step - loss: 0.1098 - accuracy: 0.9626\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 977us/step - loss: 0.1043 - accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9626\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9679\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 991us/step - loss: 0.0878 - accuracy: 0.9733\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5055 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5829\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.6553 - accuracy: 0.6310\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.6407 - accuracy: 0.6310\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7326\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.7380\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.5737 - accuracy: 0.7433\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7594\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.5289 - accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7914\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4851 - accuracy: 0.7807\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7647\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4577 - accuracy: 0.8021\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 981us/step - loss: 0.4264 - accuracy: 0.8128\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.8075\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.4151 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8235\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8128\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3808 - accuracy: 0.8449\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4011 - accuracy: 0.7861\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8556\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 960us/step - loss: 0.3738 - accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.3481 - accuracy: 0.8396\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8770\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8556\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 978us/step - loss: 0.3219 - accuracy: 0.8449\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8449\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8717\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8396\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2978 - accuracy: 0.8663\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8770\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8770\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8984\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.2602 - accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.8984\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 983us/step - loss: 0.2518 - accuracy: 0.9144\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.8877\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8770\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.8984\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8877\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.8984\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9037\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2207 - accuracy: 0.9091\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9251\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 990us/step - loss: 0.2173 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.8984\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9144\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9144\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 951us/step - loss: 0.1912 - accuracy: 0.9305\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 945us/step - loss: 0.1877 - accuracy: 0.9251\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1869 - accuracy: 0.9358\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.1807 - accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9251\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 957us/step - loss: 0.1699 - accuracy: 0.9412\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9358\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.1652 - accuracy: 0.9358\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9144\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9465\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1628 - accuracy: 0.9465\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.1596 - accuracy: 0.9412\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1552 - accuracy: 0.9465\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1471 - accuracy: 0.9572\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9572\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1493 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9626\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.1279 - accuracy: 0.9626\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1381 - accuracy: 0.9519\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9679\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0965 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9733\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1002 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9840\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.0760 - accuracy: 0.9840\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4473 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.6043\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.7059\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6524\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6898\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.7166\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6117 - accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.7487\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7754\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7701\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7754\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7861\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7914\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 0.4337 - accuracy: 0.8235\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8396\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3926 - accuracy: 0.8289\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.7968\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8342\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3595 - accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3341 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8770\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8503\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3196 - accuracy: 0.8610\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.2981 - accuracy: 0.8877\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8717\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8984\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2719 - accuracy: 0.8877\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.8984\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.8877\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.8663\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.9091\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.8984\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2416 - accuracy: 0.9037\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.8930\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2261 - accuracy: 0.9144\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9037\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9198\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9037\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.8930\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2055 - accuracy: 0.9144\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2040 - accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.9251\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9251\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9412\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9251\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9412\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9412\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9305\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9305\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9519\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1667 - accuracy: 0.9519\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.1538 - accuracy: 0.9465\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9572\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9572\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9198\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9572\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1380 - accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9412\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9572\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9465\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9572\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 950us/step - loss: 0.1136 - accuracy: 0.9679\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9465\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9733\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0871 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.0758 - accuracy: 0.9786\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2271 - accuracy: 0.9048\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.3904\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 997us/step - loss: 0.6857 - accuracy: 0.5668\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.6043\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.7059\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.7059\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.5998 - accuracy: 0.7059\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.7166\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.7861\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7594\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7433\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7594\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.8075\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8075\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7861\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7968\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.4141 - accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4117 - accuracy: 0.8289\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8289\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7754\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8128\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8289\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8289\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8396\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8449\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8556\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3587 - accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3304 - accuracy: 0.8610\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8556\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8503\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8503\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8556\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8717\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8770\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8770\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8824\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8984\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 972us/step - loss: 0.2856 - accuracy: 0.8824\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.8877\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8770\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.9037\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9037\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 983us/step - loss: 0.2727 - accuracy: 0.8770\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.9037\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9198\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8930\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.9358\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.9037\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9251\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9091\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9037\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9037\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9198\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9091\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.2325 - accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9358\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9198\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9305\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9305\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9251\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9465\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9358\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9198\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9358\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1786 - accuracy: 0.9465\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9465\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9572\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9519\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9572\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9572\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.1683 - accuracy: 0.9465\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9519\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9465\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9572\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9626\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9626\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9626\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 973us/step - loss: 0.1309 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9626\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9626\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9626\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9519\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9626\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 957us/step - loss: 0.1086 - accuracy: 0.9679\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5741 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.7144 - accuracy: 0.4681\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.6858 - accuracy: 0.5106\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5479\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6543\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6809\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6596\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.7074\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.6003 - accuracy: 0.8191\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.5830 - accuracy: 0.7713\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7872\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.8085\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 956us/step - loss: 0.5037 - accuracy: 0.8191\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7979\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8511\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4511 - accuracy: 0.8298\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.4263 - accuracy: 0.8298\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.8351\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 997us/step - loss: 0.3974 - accuracy: 0.8511\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8564\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3561 - accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8404\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8777\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8723\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 986us/step - loss: 0.3179 - accuracy: 0.8883\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 932us/step - loss: 0.3120 - accuracy: 0.8830\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8883\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 968us/step - loss: 0.2864 - accuracy: 0.8936\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.8883\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.2843 - accuracy: 0.9043\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9096\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.9096\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.9202\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.9309\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.2386 - accuracy: 0.9255\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.2295 - accuracy: 0.9309\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9202\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 984us/step - loss: 0.2381 - accuracy: 0.9202\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9255\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 986us/step - loss: 0.2176 - accuracy: 0.9362\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9415\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.1935 - accuracy: 0.9521\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9468\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.1819 - accuracy: 0.9628\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.1731 - accuracy: 0.9468\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9468\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9628\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.1615 - accuracy: 0.9521\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9521\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9787\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9734\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9681\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9681\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9681\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9681\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9787\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9734\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9894\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9681\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9787\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9894\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0835 - accuracy: 0.9894\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9894\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9894\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9787\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9894\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9947\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9894\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9947\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0593 - accuracy: 0.9947\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0680 - accuracy: 0.9894\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9894\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9894\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9947\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9894\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9947\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 974us/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9947\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 997us/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 980us/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1808 - accuracy: 0.9500\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.6518 - accuracy: 0.6223\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.6403 - accuracy: 0.6543\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6649\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.6026 - accuracy: 0.7021\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.7553\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.5697 - accuracy: 0.7340\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.5425 - accuracy: 0.7606\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.5280 - accuracy: 0.7660\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7660\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 992us/step - loss: 0.4804 - accuracy: 0.7819\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7979\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4538 - accuracy: 0.8032\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8085\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4303 - accuracy: 0.8085\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8032\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.4152 - accuracy: 0.8032\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4026 - accuracy: 0.8085\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.4126 - accuracy: 0.7926\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8191\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8085\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.3696 - accuracy: 0.8191\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.3644 - accuracy: 0.8511\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8085\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1000us/step - loss: 0.3581 - accuracy: 0.8457\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 973us/step - loss: 0.3520 - accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8617\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.3411 - accuracy: 0.8404\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8351\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8883\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8883\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8723\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8723\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8723\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.3136 - accuracy: 0.8936\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.2988 - accuracy: 0.8723\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.3079 - accuracy: 0.8936\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8883\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8723\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8777\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.8830\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.9096\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.9202\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.9096\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.9096\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8777\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.9043\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.9096\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8830\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9149\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9202\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9043\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9309\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9202\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9043\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9255\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9309\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9202\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9309\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9309\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9415\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9468\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9309\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9468\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.9415\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9255\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9415\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9415\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9468\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9574\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9521\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9574\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9415\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9574\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9628\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9362\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9574\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9468\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9574\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9521\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9574\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9734\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9681\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9681\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9681\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9734\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9628\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9734\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9681\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9787\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9681\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9787\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3895 - accuracy: 0.8500\n",
      "\n",
      " 10 fold accuracy ['0.7143', '0.7619', '0.7619', '0.8095', '0.7143', '0.8571', '0.9048', '0.8095', '0.9500', '0.8500']\n"
     ]
    }
   ],
   "source": [
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[test],Y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "    \n",
    "print('\\n %.f fold accuracy' % n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c21cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e81c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac198df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
